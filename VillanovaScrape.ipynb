{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pprint  \n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import mechanize \n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "\n",
    "#r = requests.get('http://www.listinga|llcars.com/results/New')\n",
    "#data = r.text\n",
    "#soup = BeautifulSoup(data)\n",
    "#for link in sou\n",
    "#p.find_all('a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Last year season gameid http://www.espn.com/nba/game?gameId=400899695\n",
    "#This year is from http://www.espn.com/nba/playbyplay?gameId=400900000\n",
    "#To http://www.espn.com/nba/playbyplay?gameId=400900255\n",
    "\n",
    "#Url for NBA\n",
    "# url = 'http://www.espn.com/nba/playbyplay?gameId='\n",
    "#Url for NCAAM\n",
    "url = 'http://www.espn.com/mens-college-basketball/playbyplay?gameId='\n",
    "\n",
    "#2017 NBA\n",
    "# pagestart = 400900100\n",
    "# pageend = 400900255\n",
    "\n",
    "# NCAAM\n",
    "# pagestart = 400910000\n",
    "# pageend = 400919999\n",
    "output = pd.DataFrame()\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "\n",
    "startdate = 20170126 # have to start 2 before your actual start date because of coding prep\n",
    "NBAorNCAAM = 'NCAAM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Helper functino for make or miss\n",
    "def toBinary(string):\n",
    "    if (string == 'made'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def Open_Date_Browser(NBAorNCAAM,date):\n",
    "    if NBAorNCAAM == \"NBA\":\n",
    "        url = 'http://www.espn.com/nba/schedule/_/date/'+ str(date)+'/'\n",
    "    else:\n",
    "        url = 'http://www.espn.com/mens-college-basketball/schedule/_/date/'+ str(date)+'/'\n",
    "    br.open(url)\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def scrape(text_team):\n",
    "    shot = []\n",
    "    shootername =[]\n",
    "    top = []\n",
    "    left = []\n",
    "    status = []\n",
    "    shootingteam = []\n",
    "    datatext = []\n",
    "    threepointer = []\n",
    "    assists = []\n",
    "    quarter = []\n",
    "    shooterid = []\n",
    "    \n",
    "    for x in text_team.find_all('li'):\n",
    "        status_value = str(x.get('class')[0])\n",
    "        shootingteam_value = str(x.get('data-homeaway'))\n",
    "        datatext_value = str(x.get('data-text'))\n",
    "        quarter_value = str(x.get('data-period'))\n",
    "        shooterid_value = str(x.get('data-shooter'))\n",
    "        text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "        text =text.split()\n",
    "        shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "        left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "        top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "        if ('three point' or 'three') in datatext_value:\n",
    "            threepointer_value = 1\n",
    "        else: \n",
    "            threepointer_value = 0\n",
    "        if ('(' in datatext_value and ')' in datatext_value):\n",
    "            assists_value = re.search(r'\\((.*?)\\)',datatext_value).group(1)\n",
    "        else:\n",
    "            assists_value = '0'\n",
    "        \n",
    "        if ('assists' or 'assist') in assists_value:\n",
    "            assists_value = assists_value[0:len(assists_value)-8]\n",
    "        else: \n",
    "            assists_value = '0'\n",
    "        if datatext_value.find('makes') != -1:\n",
    "            shootername_value = datatext_value[0:datatext_value.find('makes')-1]\n",
    "        elif datatext_value.find('made') != -1:\n",
    "            shootername_value = datatext_value[0:datatext_value.find('made')-1]\n",
    "        elif datatext_value.find('misses') != -1:\n",
    "            shootername_value = datatext_value[0:datatext_value.find('misses')-1]\n",
    "        elif datatext_value.find('missed') != -1:\n",
    "            shootername_value = datatext_value[0:datatext_value.find('missed')-1]\n",
    "        elif ('blocks' in datatext_value) or ('block' in datatext_value):\n",
    "            a = datatext_value.rindex('blocks')\n",
    "            b = datatext_value.rindex(\"'\")\n",
    "            shootername_value = datatext_value[a+len('blocks')+1:b]\n",
    "        while shootername_value[len(shootername_value)-1]==' ':\n",
    "            shootername_value = shootername_value[0:len(shootername_value)-1]\n",
    "            \n",
    "        shootername.append(shootername_value)\n",
    "        shootingteam.append(shootingteam_value)\n",
    "        shot.append(shot_value)\n",
    "        top.append(top_value)\n",
    "        left.append(left_value)\n",
    "        status.append(toBinary(status_value))\n",
    "        datatext.append(datatext_value)\n",
    "        threepointer.append(threepointer_value)\n",
    "        assists.append(assists_value)\n",
    "        quarter.append(quarter_value)\n",
    "        shooterid.append(shooterid_value)\n",
    "    \n",
    "    shootername = np.array(shootername)\n",
    "    shootingteam = np.array(shootingteam)\n",
    "    shot = np.array(shot)\n",
    "    top = np.array(top)\n",
    "    left = np.array(left)\n",
    "    status = np.array(status)\n",
    "    datatext = np.array(datatext)\n",
    "    threepointer = np.array(threepointer)\n",
    "    assists = np.array(assists)\n",
    "    shooterid = np.array(shooterid)\n",
    "    quarter = np.array(quarter)\n",
    "\n",
    "    return shootingteam, shot, top, left, status, datatext, threepointer,assists, shootername, quarter, shooterid\n",
    "\n",
    "def scrapeDate(soup):\n",
    "    try:\n",
    "        date = soup.find('div',{'class' : 'cscore_date-time'}).get('data-date')[0:10]\n",
    "    except:\n",
    "        try:\n",
    "            title = soup.title.text\n",
    "            date = title[title.find(\"Play -\")+len(\"Play -\")+1:title.find(\"- ESPN\")-1]\n",
    "        except:\n",
    "            date = \"Error in Scraping Date\"\n",
    "    return date\n",
    "\n",
    "def scrapeTeams(soup):\n",
    "    try:\n",
    "        teams =  soup.find_all('span',{'class' : 'cscore_name cscore_name--long'})\n",
    "        home_team = teams[1].contents\n",
    "        away_team = teams[0].contents\n",
    "    except:\n",
    "        try:\n",
    "            title = soup.title.text\n",
    "            away_team = title[0:title.find(\"vs.\")-1]\n",
    "            home_team = title[title.find(\"vs.\")+4:title.find(\"- Play-By-Play\")-1]\n",
    "        except:\n",
    "            home_team = \"Error in Team Scrape\"\n",
    "            away_team = \"Error in Team Scrape\"\n",
    "    return home_team, away_team\n",
    "\n",
    "#Download Game IDs\n",
    "def ScrapeGameID(date,NBAorNCAAM):\n",
    "    gameID = []\n",
    "    soup = Open_Date_Browser(NBAorNCAAM, date)\n",
    "    if (\"No games scheduled\" in soup.text) == False:\n",
    "        test = soup.find('section', { \"class\" : \"col-a\" })\n",
    "        for row in test.find_all('a'):\n",
    "            if 'gameId' in row.get('href'):\n",
    "                href = row.get('href')\n",
    "                gameID.append(href[-9:])\n",
    "    return gameID\n",
    "\n",
    "def int2Date(startdate):\n",
    "    date = datetime.datetime(int(str(startdate)[0:4]),int(str(startdate)[4:6]),int(str(startdate)[6:8]))\n",
    "    return date\n",
    "\n",
    "    \n",
    "def incrementDate(date):\n",
    "    date = date + datetime.timedelta(days=1)\n",
    "    a = datetime.date(date.year,date.month,date.day)\n",
    "    a = str(a)\n",
    "    a = a.replace(\"-\",\"\")\n",
    "    return a, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# soup = Open_Browser(url, 400917636)\n",
    "# print soup\n",
    "# #print soup.find_all('data-date')\n",
    "# # print soup.find('div',{'class' : 'cscore_date-time'}).get('data-date')[0:10]\n",
    "\n",
    "# # for a in soup.find_all('div',{'class' : 'cscore_date-time'}):\n",
    "# #     print a.get('data-date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# date = datetime.datetime(2016,12,22)\n",
    "# print type(date)\n",
    "\n",
    "# for i in range(50): \n",
    "#     date += datetime.timedelta(days=1)\n",
    "#     a = datetime.date(date.year,date.month,date.day)\n",
    "#     a = str(a)\n",
    "#     a = a.replace(\"-\",\"\")\n",
    "#     print(a) \n",
    "# print date\n",
    "# print str(startdate)[0:4]\n",
    "# print str(startdate)[4:6]\n",
    "# print str(startdate)[6:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20170314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print startdate\n",
    "# startdate = 2014010\n",
    "# t0, t1 = incrementDate(int2Date(startdate))\n",
    "# print t0\n",
    "# gameID = ScrapeGameID(t0,NBAorNCAAM)\n",
    "# print gameID\n",
    "\n",
    "int(str(datetime.date.today()).replace(\"-\",''))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170128\n",
      "20170129\n",
      "20170130\n",
      "20170131\n",
      "20170201\n",
      "20170202\n",
      "20170203\n",
      "20170204\n",
      "20170205\n",
      "20170206\n",
      "20170207\n",
      "20170208\n"
     ]
    }
   ],
   "source": [
    "t0, t1 = incrementDate(int2Date(startdate))\n",
    "while int(t0) != int(str(datetime.date.today()).replace(\"-\",''))-1:\n",
    "    t0, t1 = incrementDate(t1)\n",
    "    try:\n",
    "        gameID = ScrapeGameID(t0,NBAorNCAAM)\n",
    "    except:\n",
    "        try:\n",
    "            print 'error'\n",
    "            time.sleep(150)\n",
    "            gameID = ScrapeGameID(t0,NBAorNCAAM)\n",
    "        except:\n",
    "                try:\n",
    "                    print 'error 2'\n",
    "                    time.sleep(300)\n",
    "                    gameID = ScrapeGameID(t0,NBAorNCAAM)\n",
    "                except:\n",
    "                    print 'error 3'\n",
    "                    time.sleep(600)\n",
    "                    gameID = ScrapeGameID(t0,NBAorNCAAM)\n",
    "    print t0\n",
    "    for page in range(0,len(gameID)):\n",
    "        try:\n",
    "            soup = Open_Browser(url, gameID[page])\n",
    "            date = scrapeDate(soup)\n",
    "            home_team, away_team = scrapeTeams(soup)\n",
    "    \n",
    "            text_home_team = soup.find('ul', { \"class\" : \"shots home-team\" })\n",
    "            text_away_team = soup.find('ul', { \"class\" : \"shots away-team\" })\n",
    "            if text_home_team == None or text_away_team == None:\n",
    "                continue\n",
    "\n",
    "            shootingteam,shot,top,left,status, datatext, threepointer,assists, shootername,quarter, shooterid = scrape(text_home_team)\n",
    "            HomeTeam = pd.DataFrame({'Date' : str(date),'Shooting Team': shootingteam,'Shooter Name' : shootername,'Shooter ID':shooterid,'Shot Number':shot,\n",
    "                                     'Quarter':quarter,'Left Position': left,'Top Position': top,'Home Team': home_team,\n",
    "                                    'Away Team': away_team,'Shot Status': status,'Three Pointer': threepointer,\n",
    "                                     'Assists': assists,'Text':datatext})\n",
    "\n",
    "            shootingteam,shot,top,left,status,datatext,threepointer,assists, shootername,quarter, shooterid = scrape(text_away_team)\n",
    "            AwayTeam = pd.DataFrame({'Date' : str(date),'Shooting Team': shootingteam,'Shooter Name' : shootername,'Shooter ID':shooterid,'Shot Number':shot,\n",
    "                                     'Quarter':quarter,'Left Position': left,'Top Position': top,'Home Team': home_team,\n",
    "                                    'Away Team': away_team,'Shot Status': status,'Three Pointer' : threepointer,\n",
    "                                     'Assists': assists,'Text':datatext})\n",
    "\n",
    "            HomeTeam = HomeTeam[['Date','Shooting Team','Shooter Name','Shooter ID','Shot Number','Quarter','Left Position','Top Position','Home Team','Away Team',\n",
    "                                 'Shot Status','Three Pointer','Assists', 'Text']]\n",
    "            AwayTeam = AwayTeam[['Date','Shooting Team','Shooter Name','Shooter ID','Shot Number','Quarter','Left Position','Top Position','Home Team','Away Team',\n",
    "                                 'Shot Status','Three Pointer','Assists','Text']]\n",
    "\n",
    "            frames = [HomeTeam, AwayTeam]\n",
    "            current_output = pd.concat(frames)\n",
    "            output = output.append(current_output)\n",
    "        except Exception as e: \n",
    "            if 'forcibly closed' in str(e):\n",
    "                time.sleep(300)\n",
    "                page = page - 1\n",
    "            else: \n",
    "                print str(e) + str(gameID[page])\n",
    "    #     except ValueError:\n",
    "    #         print \"Error on page \" + str(page)\n",
    "    #     except:\n",
    "    #         print \"Other Error\"\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s = \"Andre 'Drummond' b'locks 'Garrett Temple 's 2-foot  layup\"\n",
    "\n",
    "# 'blocks' in s\n",
    "# b = s.rindex(\"'\")\n",
    "\n",
    "# print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################Write Dataframe to .csv\n",
    "output.to_csv('C:\\Users\\gordon.tsai\\Google Drive\\MarchMadnessScrape.csv', sep = ',', encoding = 'utf-8' , index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
