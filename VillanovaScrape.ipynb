{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pprint  \n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import mechanize \n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "#r = requests.get('http://www.listingallcars.com/results/New')\n",
    "#data = r.text\n",
    "#soup = BeautifulSoup(data)\n",
    "#for link in sou\n",
    "#p.find_all('a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot0 top:32%\n",
      "shot3 top:50%\n",
      "shot4 top:56%\n",
      "shot5 top:52%\n",
      "shot6 top:48%\n",
      "shot7 top:50%\n",
      "shot8 top:86%\n",
      "shot9 top:50%\n",
      "shot10 top:52%\n",
      "shot11 top:58%\n",
      "shot12 top:54%\n",
      "shot13 top:50%\n",
      "shot14 top:92%\n",
      "shot15 top:96%\n",
      "shot16 top:50%\n",
      "shot17 top:54%\n",
      "shot20 top:56%\n",
      "shot21 top:74%\n",
      "shot22 top:70%\n",
      "shot23 top:54%\n",
      "shot24 top:88%\n",
      "shot25 top:66%\n",
      "shot26 top:32%\n",
      "shot29 top:28%\n",
      "shot30 top:22%\n",
      "shot31 top:46%\n",
      "shot34 top:54%\n",
      "shot35 top:86%\n",
      "shot36 top:96%\n",
      "shot40 top:52%\n",
      "shot41 top:56%\n",
      "shot42 top:50%\n",
      "shot43 top:48%\n",
      "shot46 top:32%\n",
      "shot47 top:34%\n",
      "shot50 top:54%\n",
      "shot51 top:66%\n",
      "shot52 top:18%\n",
      "shot53 top:50%\n",
      "shot54 top:72%\n",
      "shot55 top:66%\n",
      "shot56 top:50%\n",
      "shot57 top:38%\n",
      "shot60 top:16%\n",
      "shot61 top:72%\n",
      "shot62 top:64%\n",
      "shot63 top:56%\n",
      "shot64 top:52%\n",
      "shot65 top:62%\n",
      "shot66 top:62%\n",
      "shot69 top:40%\n",
      "shot70 top:54%\n",
      "shot71 top:46%\n",
      "shot73 top:60%\n",
      "shot74 top:84%\n",
      "shot75 top:52%\n",
      "shot78 top:96%\n",
      "shot79 top:96%\n",
      "shot83 top:84%\n",
      "shot84 top:74%\n",
      "shot85 top:84%\n",
      "shot88 top:72%\n",
      "shot89 top:44%\n",
      "shot90 top:46%\n",
      "shot93 top:84%\n",
      "shot94 top:76%\n",
      "shot97 top:20%\n",
      "shot98 top:16%\n",
      "shot99 top:54%\n",
      "shot100 top:50%\n",
      "shot101 top:16%\n",
      "shot102 top:64%\n",
      "shot103 top:70%\n",
      "shot104 top:70%\n",
      "shot105 top:34%\n",
      "shot106 top:86%\n",
      "shot107 top:96%\n",
      "shot108 top:82%\n",
      "shot113 top:54%\n",
      "shot114 top:66%\n",
      "shot115 top:10%\n",
      "shot116 top:46%\n",
      "shot117 top:10%\n"
     ]
    }
   ],
   "source": [
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "url = 'http://www.espn.com/nba/playbyplay?gameId=400900084'\n",
    "# #url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "br.open(url)\n",
    "response = br.response()\n",
    "soup = BeautifulSoup(response,\"html.parser\")\n",
    "#print soup.prettify()\n",
    "\n",
    "test = soup.find('ul', { \"class\" : \"shots home-team\" })\n",
    "# lis = []\n",
    "# for ul in uls:\n",
    "#     for li in ul.findAll('li'):\n",
    "#         if li.find('ul'):\n",
    "#             break\n",
    "#         lis.append(li)\n",
    "\n",
    "# for li in lis:\n",
    "#     print li.text.encode(\"utf-8\")\n",
    "\n",
    "# total_cars = str(soup.body.h1.text)\n",
    "# total_cars = int(total_cars[0:len(total_cars)-30-len(cartype)].replace(',',''))\n",
    "# # print soup.find_all('select',{\"class\":\"col-md-12 form-control\"})\n",
    "\n",
    "for x in test.find_all('li'):\n",
    "    print('{} {}'.format(x.get('id'), x.get('style').split(';')[-2]))\n",
    "\n",
    "\n",
    "#soup = BeautifulSoup(response,\"html.parser\")\n",
    "# # for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "# #     carname.append(row.text)    \n",
    "# # for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "# #     price.append(row.text[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_change(car_make = None ,model = None , price_interval = None, body = None,colors = None):\n",
    "    url = 'http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017'\n",
    "    if car_make != None:\n",
    "        url = url +'/make-'+car_make\n",
    "    if model != None:\n",
    "        url = url + '/model-'+model\n",
    "    if colors != None:\n",
    "        url = url + '/extcolor-'+colors\n",
    "    if body != None:\n",
    "        url = url + '/body-'+body\n",
    "    if price_interval != None:\n",
    "        url = url + '/price-'+price_interval\n",
    "    url = url + '/sort-1/page-'\n",
    "    return url\n",
    "\n",
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def web2var(string):\n",
    "    string = string.replace('+','')\n",
    "    string = string.replace('-','')\n",
    "    return string\n",
    "\n",
    "def var2web(string):\n",
    "    if ' ' in string:\n",
    "        string = string.replace(' ','+')\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "carname = []\n",
    "# print key_list[11]\n",
    "# print Car_Make[11]\n",
    "# print modelDictionary[key_list[11]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,653 New  Acura Cars for Sale in the USA\n",
      "18653\n",
      "http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017/make-Acura/sort-1/page-\n",
      "0 New Acura CL Cars for Sale in the USA\n",
      "0\n",
      "http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017/make-Acura/model-CL/sort-1/page-\n",
      "0\n",
      "2,853 New Acura ILX Cars for Sale in the USA\n",
      "2853\n",
      "http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017/make-Acura/model-ILX/sort-1/page-\n",
      "2853\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#@Deprecated\n",
    "# def Total_Trucks(soup, cartype, body=None): \n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "def Total_Cars(soup, cartype):\n",
    "    total_cars = str(soup.body.h1.text)\n",
    "    print total_cars\n",
    "    total_cars = total_cars.replace(',','')\n",
    "    total_cars = int(re.search(r'\\d+', total_cars).group())\n",
    "#   total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "    print total_cars\n",
    "    total_cars= int(total_cars)\n",
    "    return total_cars\n",
    "    \n",
    "#46010 is total\n",
    "#i = 1\n",
    "#haven't done Chevrolet because they have a lot (175k)\n",
    "# i = 12 is cheverolet\n",
    "#for i in range(12,len(Car_Make)):\n",
    "\n",
    "for i in range(1,len(Car_Make)):\n",
    "    url = url_change(Car_Make[i])\n",
    "    soup = Open_Browser(url, i)\n",
    "    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    print url;\n",
    "    #     print total_cars\n",
    "    if total_cars > 3000:\n",
    "        #model iteration\n",
    "        for h in range(0 , len(modelDictionary[key_list[i]])):\n",
    "            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h])\n",
    "            soup = Open_Browser(url, i)\n",
    "            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "            print url\n",
    "            print total_cars\n",
    "            if total_cars > 3000:\n",
    "                for k in range(0 , len(Price_Interval)):\n",
    "                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k])\n",
    "                    soup = Open_Browser(url, i)\n",
    "                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                    print url\n",
    "                    print total_cars\n",
    "                    if total_cars > 3000:\n",
    "                        for l in range(0 , len(Body)):\n",
    "                            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l])\n",
    "                            soup = Open_Browser(url, i)\n",
    "                            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                            print url\n",
    "                            print total_cars\n",
    "                            if total_cars > 3000:\n",
    "                                for j in range(0,len(Colors)):\n",
    "                                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l],Colors[j])\n",
    "                                    soup = Open_Browser(url, i)\n",
    "                                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                                    print url\n",
    "                                    print total_cars\n",
    "                            else:\n",
    "                                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                                    soup = Open_Browser(url,page)\n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                        carname.append(row.text)    \n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                        price.append(row.text[8:])\n",
    "                                    print page\n",
    "                    else:\n",
    "                        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                            soup = Open_Browser(url,page)\n",
    "                            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                carname.append(row.text)    \n",
    "                            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                price.append(row.text[8:])\n",
    "                            print page  \n",
    "            else:\n",
    "                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                    soup = Open_Browser(url,page)\n",
    "                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                        carname.append(row.text)    \n",
    "                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                        price.append(row.text[8:])\n",
    "                    print page\n",
    "    else:\n",
    "        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "            soup = Open_Browser(url,page)\n",
    "            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                carname.append(row.text)    \n",
    "            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                price.append(row.text[8:])\n",
    "            print page\n",
    "\n",
    "\n",
    "print 'Done'\n",
    "                            \n",
    "#     count = count +1\n",
    "#     url_change = url + str(i)\n",
    "#     br.open(url_change)\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "#         carname.append(row.text)    \n",
    "#     for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "#         price.append(row.text[8:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ####Browser mechanize functionality\n",
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "\n",
    "\n",
    "# #Used to count and figure out which ones are over 3000 even after Body type\n",
    "# def Open_Browser(url, page):\n",
    "#     br.open(url+str(page))\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     return soup\n",
    "\n",
    "# def Total_Trucks(soup, cartype, body=None):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "# def Total_Cars(soup, cartype):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "    \n",
    "# #46010 is total\n",
    "# for i in range(1,len(Car_Make)):\n",
    "#     url = url_change(Car_Make[i])\n",
    "#     soup = Open_Browser(url, i)\n",
    "#     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#     print url;\n",
    "#     print total_cars\n",
    "#     if total_cars > 3000:\n",
    "#         print total_cars > 3000\n",
    "#         for j in range(1,len(Price_Interval)):\n",
    "#             url = url_change(Car_Make[i], Price_Interval[j])\n",
    "#             soup = Open_Browser(url, i)\n",
    "#             total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#             print url\n",
    "#             print total_cars\n",
    "# #     else:\n",
    "#             if total_cars > 3000:\n",
    "#                 for k in range(1 , len(Colors)):\n",
    "#                     url = url_change(Car_Make[i], Price_Interval[j], Colors[k])\n",
    "#                     soup = Open_Browser(url, i)\n",
    "#                     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#                     print url\n",
    "#                     print total_cars\n",
    "# #             else:\n",
    "#                     if total_cars > 3000:\n",
    "#                         for l in range(1 , len(Body)):\n",
    "#                             url = url_change(Car_Make[i], Price_Interval[j], Colors[k],Body[l])\n",
    "#                             soup = Open_Browser(url, i)\n",
    "#                             total_cars = Total_Trucks(soup, Car_Make[i], Body[l])\n",
    "#                             print url\n",
    "#                             print total_cars\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mechanize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-669b9c05da7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmechanize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBrowser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmechanize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRobustFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcartype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Rolls-Royce'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.espn.com/nba/playbyplay?gameId=400900084'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# #url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# br.open(url+str(1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mechanize' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################Write Dataframe to .csv\n",
    "output = pd.DataFrame(price,carname)\n",
    "#print(output)\n",
    "output.to_csv('CarPriceDistribution.csv', sep = ',', encoding = 'utf-8' )\n",
    "\n",
    "print len(price)\n",
    "#print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
