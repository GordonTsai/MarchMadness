{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pprint  \n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import mechanize \n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "#r = requests.get('http://www.listingallcars.com/results/New')\n",
    "#data = r.text\n",
    "#soup = BeautifulSoup(data)\n",
    "#for link in sou\n",
    "#p.find_all('a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "url = 'http://www.espn.com/nba/playbyplay?gameId=400900084'\n",
    "# #url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "br.open(url)\n",
    "response = br.response()\n",
    "soup = BeautifulSoup(response,\"html.parser\")\n",
    "#print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teams =  soup.find_all('span',{'class' : 'cscore_name cscore_name--long'})\n",
    "home_team = teams[0].contents\n",
    "away_team = teams[1].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Helper functino for make or miss\n",
    "def toBinary(string):\n",
    "    if (string == 'made'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_home_team = soup.find('ul', { \"class\" : \"shots home-team\" })\n",
    "text_away_team = soup.find('ul', { \"class\" : \"shots away-team\" })\n",
    "shot_home = []\n",
    "shot_away = []\n",
    "top_home = []\n",
    "top_away = []\n",
    "left_home = []\n",
    "left_away = []\n",
    "status_home = []\n",
    "status_away = []\n",
    "shooting_team_home = []\n",
    "shooting_team_away = []\n",
    "\n",
    "for x in text_home_team.find_all('li'):\n",
    "    status = str(x.get('class')[0])\n",
    "    text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "    text =text.split()\n",
    "    shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "    left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "    top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "    shot_home.append(shot_value)\n",
    "    top_home.append(top_value)\n",
    "    left_home.append(left_value)\n",
    "    status_home.append(toBinary(status))\n",
    "\n",
    "for x in text_away_team.find_all('li'):\n",
    "    status = str(x.get('class')[0])\n",
    "    text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "    text =text.split()\n",
    "    shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "    left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "    top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "    shot_away.append(shot_value)\n",
    "    top_away.append(top_value)\n",
    "    left_away.append(left_value)\n",
    "    status_away.append(toBinary(status))\n",
    "\n",
    "shot_home = np.array(shot_home)\n",
    "top_home = np.array(top_home)\n",
    "left_home = np.array(left_home)\n",
    "status_home = np.array(status_home)\n",
    "\n",
    "shot_away = np.array(shot_away)\n",
    "top_away = np.array(top_away)\n",
    "left_away = np.array(left_away)\n",
    "status_away = np.array(status_away)\n",
    "\n",
    "# print shot_home.shape\n",
    "# print top_home.shape\n",
    "# print left_home.shape\n",
    "# print shooting_team_home.shape\n",
    "# print status_home.shape\n",
    "\n",
    "\n",
    "# print len(shot_home)\n",
    "# print len(top_home)\n",
    "# print len(left_home)\n",
    "# print len(shooting_team_home)\n",
    "# print len(status_home)\n",
    "\n",
    "\n",
    "HomeTeam = pd.DataFrame({'Shooting Team': home_team*len(shot_home),'Shot Number':shot_home,\n",
    "                         'Left Position': left_home,'Top Position': top_home,'Home Team': home_team*(len(shot_home)),\n",
    "                        'Away Team': away_team*len(shot_home),'Shot Status': status_home})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AwayTeam = pd.DataFrame({'Shooting Team': away_team*len(shot_away),'Shot Number':shot_away,\n",
    "                         'Left Position': left_away,'Top Position': top_away,'Home Team': home_team*(len(shot_away)),\n",
    "                        'Away Team': away_team*len(shot_away),'Shot Status': status_away})\n",
    "HomeTeam = HomeTeam[['Shooting Team','Shot Number','Left Position','Top Position','Home Team','Away Team','Shot Status']]\n",
    "AwayTeam = AwayTeam[['Shooting Team','Shot Number','Left Position','Top Position','Home Team','Away Team','Shot Status']]\n",
    "\n",
    "    \n",
    "# print('{} {}'.format(x.get('id'), x.get('style').split(';')[-2]))    \n",
    "\n",
    "#soup = BeautifulSoup(response,\"html.parser\")\n",
    "# # for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "# #     carname.append(row.text)    \n",
    "# # for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "# #     price.append(row.text[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in text_home_team.find_all('li'):\n",
    "    print str(x.get('class')[0])\n",
    "    print toBinary(str(x.get('class')[0]))\n",
    "    \n",
    "    text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "    print text\n",
    "#     text =text.split()\n",
    "#     shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "#     left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "#     top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "#     shot_home.append(shot_value)\n",
    "#     top_home.append(top_value)\n",
    "#     left_home.append(left_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shooting Team Shot Number  Left Position  Top Position     Home Team  \\\n",
      "0  Phoenix Suns           0           0.90          0.32  Phoenix Suns   \n",
      "1  Phoenix Suns           3           0.94          0.50  Phoenix Suns   \n",
      "2  Phoenix Suns           4           0.94          0.56  Phoenix Suns   \n",
      "3  Phoenix Suns           5           0.92          0.52  Phoenix Suns   \n",
      "4  Phoenix Suns           6           0.92          0.48  Phoenix Suns   \n",
      "\n",
      "         Away Team  Shot Status  \n",
      "0  Toronto Raptors            1  \n",
      "1  Toronto Raptors            1  \n",
      "2  Toronto Raptors            0  \n",
      "3  Toronto Raptors            1  \n",
      "4  Toronto Raptors            1  \n"
     ]
    }
   ],
   "source": [
    "print HomeTeam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "`def url_change(car_make = None ,model = None , price_interval = None, body = None,colors = None):\n",
    "    url = 'http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017'\n",
    "    if car_make != None:\n",
    "        url = url +'/make-'+car_make\n",
    "    if model != None:\n",
    "        url = url + '/model-'+model\n",
    "    if colors != None:\n",
    "        url = url + '/extcolor-'+colors\n",
    "    if body != None:\n",
    "        url = url + '/body-'+body\n",
    "    if price_interval != None:\n",
    "        url = url + '/price-'+price_interval\n",
    "    url = url + '/sort-1/page-'\n",
    "    return url\n",
    "\n",
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def web2var(string):\n",
    "    string = string.replace('+','')\n",
    "    string = string.replace('-','')\n",
    "    return string\n",
    "\n",
    "def var2web(string):\n",
    "    if ' ' in string:\n",
    "        string = string.replace(' ','+')\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "carname = []\n",
    "# print key_list[11]\n",
    "# print Car_Make[11]\n",
    "# print modelDictionary[key_list[11]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#@Deprecated\n",
    "# def Total_Trucks(soup, cartype, body=None): \n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "def Total_Cars(soup, cartype):\n",
    "    total_cars = str(soup.body.h1.text)\n",
    "    print total_cars\n",
    "    total_cars = total_cars.replace(',','')\n",
    "    total_cars = int(re.search(r'\\d+', total_cars).group())\n",
    "#   total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "    print total_cars\n",
    "    total_cars= int(total_cars)\n",
    "    return total_cars\n",
    "    \n",
    "#46010 is total\n",
    "#i = 1\n",
    "#haven't done Chevrolet because they have a lot (175k)\n",
    "# i = 12 is cheverolet\n",
    "#for i in range(12,len(Car_Make)):\n",
    "\n",
    "for i in range(1,len(Car_Make)):\n",
    "    url = url_change(Car_Make[i])\n",
    "    soup = Open_Browser(url, i)\n",
    "    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    print url;\n",
    "    #     print total_cars\n",
    "    if total_cars > 3000:\n",
    "        #model iteration\n",
    "        for h in range(0 , len(modelDictionary[key_list[i]])):\n",
    "            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h])\n",
    "            soup = Open_Browser(url, i)\n",
    "            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "            print url\n",
    "            print total_cars\n",
    "            if total_cars > 3000:\n",
    "                for k in range(0 , len(Price_Interval)):\n",
    "                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k])\n",
    "                    soup = Open_Browser(url, i)\n",
    "                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                    print url\n",
    "                    print total_cars\n",
    "                    if total_cars > 3000:\n",
    "                        for l in range(0 , len(Body)):\n",
    "                            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l])\n",
    "                            soup = Open_Browser(url, i)\n",
    "                            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                            print url\n",
    "                            print total_cars\n",
    "                            if total_cars > 3000:\n",
    "                                for j in range(0,len(Colors)):\n",
    "                                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l],Colors[j])\n",
    "                                    soup = Open_Browser(url, i)\n",
    "                                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                                    print url\n",
    "                                    print total_cars\n",
    "                            else:\n",
    "                                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                                    soup = Open_Browser(url,page)\n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                        carname.append(row.text)    \n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                        price.append(row.text[8:])\n",
    "                                    print page\n",
    "                    else:\n",
    "                        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                            soup = Open_Browser(url,page)\n",
    "                            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                carname.append(row.text)    \n",
    "                            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                price.append(row.text[8:])\n",
    "                            print page  \n",
    "            else:\n",
    "                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                    soup = Open_Browser(url,page)\n",
    "                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                        carname.append(row.text)    \n",
    "                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                        price.append(row.text[8:])\n",
    "                    print page\n",
    "    else:\n",
    "        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "            soup = Open_Browser(url,page)\n",
    "            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                carname.append(row.text)    \n",
    "            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                price.append(row.text[8:])\n",
    "            print page\n",
    "\n",
    "\n",
    "print 'Done'\n",
    "                            \n",
    "#     count = count +1\n",
    "#     url_change = url + str(i)\n",
    "#     br.open(url_change)\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "#         carname.append(row.text)    \n",
    "#     for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "#         price.append(row.text[8:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ####Browser mechanize functionality\n",
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "\n",
    "\n",
    "# #Used to count and figure out which ones are over 3000 even after Body type\n",
    "# def Open_Browser(url, page):\n",
    "#     br.open(url+str(page))\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     return soup\n",
    "\n",
    "# def Total_Trucks(soup, cartype, body=None):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "# def Total_Cars(soup, cartype):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "    \n",
    "# #46010 is total\n",
    "# for i in range(1,len(Car_Make)):\n",
    "#     url = url_change(Car_Make[i])\n",
    "#     soup = Open_Browser(url, i)\n",
    "#     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#     print url;\n",
    "#     print total_cars\n",
    "#     if total_cars > 3000:\n",
    "#         print total_cars > 3000\n",
    "#         for j in range(1,len(Price_Interval)):\n",
    "#             url = url_change(Car_Make[i], Price_Interval[j])\n",
    "#             soup = Open_Browser(url, i)\n",
    "#             total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#             print url\n",
    "#             print total_cars\n",
    "# #     else:\n",
    "#             if total_cars > 3000:\n",
    "#                 for k in range(1 , len(Colors)):\n",
    "#                     url = url_change(Car_Make[i], Price_Interval[j], Colors[k])\n",
    "#                     soup = Open_Browser(url, i)\n",
    "#                     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#                     print url\n",
    "#                     print total_cars\n",
    "# #             else:\n",
    "#                     if total_cars > 3000:\n",
    "#                         for l in range(1 , len(Body)):\n",
    "#                             url = url_change(Car_Make[i], Price_Interval[j], Colors[k],Body[l])\n",
    "#                             soup = Open_Browser(url, i)\n",
    "#                             total_cars = Total_Trucks(soup, Car_Make[i], Body[l])\n",
    "#                             print url\n",
    "#                             print total_cars\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################Write Dataframe to .csv\n",
    "output = pd.DataFrame(price,carname)\n",
    "#print(output)\n",
    "output.to_csv('CarPriceDistribution.csv', sep = ',', encoding = 'utf-8' )\n",
    "\n",
    "print len(price)\n",
    "#print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
