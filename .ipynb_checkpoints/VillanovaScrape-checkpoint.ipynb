{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pprint  \n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import mechanize \n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "#r = requests.get('http://www.listingallcars.com/results/New')\n",
    "#data = r.text\n",
    "#soup = BeautifulSoup(data)\n",
    "#for link in sou\n",
    "#p.find_all('a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "url = 'http://www.espn.com/nba/playbyplay?gameId=400900084'\n",
    "# #url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "br.open(url)\n",
    "response = br.response()\n",
    "soup = BeautifulSoup(response,\"html.parser\")\n",
    "#print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teams =  soup.find_all('span',{'class' : 'cscore_name cscore_name--long'})\n",
    "home_team = teams[0].contents\n",
    "away_team = teams[1].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Helper functino for make or miss\n",
    "def toBinary(string):\n",
    "    if (string == 'made'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "83\n",
      "79\n",
      "79\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1874408daa4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m HomeTeam = pd.DataFrame({'Shooting Team': shooting_team_home,'Shot Number':shot_home,'Left Position': left_home,\n\u001b[1;32m     57\u001b[0m                          \u001b[0;34m'Top Position'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtop_home\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Home Team'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhome_team\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshot_home\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                         'Away Team': away_team*len(shot_home),'Shot Status': status_home})\n\u001b[0m\u001b[1;32m     59\u001b[0m AwayTeam = pd.DataFrame({'Shooting Team': shooting_team_away,'Shot Number':shot_away,'Left Position': left_away,\n\u001b[1;32m     60\u001b[0m                          \u001b[0;34m'Top Position'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtop_away\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Home Team'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhome_team\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshot_away\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gordontsai/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    222\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    223\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gordontsai/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gordontsai/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5235\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5236\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5238\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gordontsai/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5544\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5545\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 5546\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   5547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gordontsai/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2920\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2921\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "text_home_team = soup.find('ul', { \"class\" : \"shots home-team\" })\n",
    "text_away_team = soup.find('ul', { \"class\" : \"shots away-team\" })\n",
    "shot_home = []\n",
    "top_home = []\n",
    "left_home = []\n",
    "status_home = []\n",
    "shot_away = []\n",
    "top_away = []\n",
    "left_away = []\n",
    "status_away = []\n",
    "shooting_team_home = []\n",
    "shooting_team_away = []\n",
    "\n",
    "for x in text_home_team.find_all('li'):\n",
    "    status = str(x.get('class')[0])\n",
    "    text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "    text =text.split()\n",
    "    shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "    left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "    top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "    shooting_team_home.append(home_team)\n",
    "    shot_home.append(shot_value)\n",
    "    top_home.append(top_value)\n",
    "    left_home.append(left_value)\n",
    "    status_home.append(toBinary(status))\n",
    "\n",
    "for x in text_away_team.find_all('li'):\n",
    "    status = str(x.get('class')[0])\n",
    "    text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "    text =text.split()\n",
    "    shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "    left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "    top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "    shooting_team_away.append(away_team)\n",
    "    shot_away.append(shot_value)\n",
    "    top_away.append(top_value)\n",
    "    left_away.append(left_value)\n",
    "    status_away.append(toBinary(status))\n",
    "\n",
    "shot_home = np.array(shot_home)\n",
    "top_home = np.array(top_home)\n",
    "left_home = np.array(left_home)\n",
    "status_home = np.array(status_home)\n",
    "shooting_team_home = np.array(shooting_team_home)\n",
    "\n",
    "shot_away = np.array(shot_away)\n",
    "top_away = np.array(top_away)\n",
    "left_away = np.array(left_away)\n",
    "status_away = np.array(status_away)\n",
    "shooting_team_away = np.array(shooting_team_away)\n",
    "print len(status_home)\n",
    "print len(shot_home)\n",
    "print len(shot_away)\n",
    "print len(status_away)\n",
    "\n",
    "HomeTeam = pd.DataFrame({'Shooting Team': shooting_team_home,'Shot Number':shot_home,'Left Position': left_home,\n",
    "                         'Top Position': top_home,'Home Team': home_team*(len(shot_home)),\n",
    "                        'Away Team': away_team*len(shot_home),'Shot Status': status_home})\n",
    "\n",
    "AwayTeam = pd.DataFrame({'Shooting Team': shooting_team_away,'Shot Number':shot_away,'Left Position': left_away,\n",
    "                         'Top Position': top_away,'Home Team': home_team*(len(shot_away)),\n",
    "                        'Away Team': away_team*len(shot_away),'Shot Status': status_away})\n",
    "HomeTeam = HomeTeam[['Shooting Team','Shot Number','Left Position','Top Position','Home Team','Away Team','Shot Status']]\n",
    "AwayTeam = AwayTeam[['Shooting Team','Shot Number','Left Position','Top Position','Home Team','Away Team','Shot Status']]\n",
    "\n",
    "    \n",
    "# print('{} {}'.format(x.get('id'), x.get('style').split(';')[-2]))    \n",
    "\n",
    "#soup = BeautifulSoup(response,\"html.parser\")\n",
    "# # for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "# #     carname.append(row.text)    \n",
    "# # for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "# #     price.append(row.text[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made\n",
      "1\n",
      "shot0 [u'left:90%', u'top:32%']\n",
      "made\n",
      "1\n",
      "shot3 [u'left:94%', u'top:50%']\n",
      "missed\n",
      "0\n",
      "shot4 [u'left:94%', u'top:56%']\n",
      "made\n",
      "1\n",
      "shot5 [u'left:92%', u'top:52%']\n",
      "made\n",
      "1\n",
      "shot6 [u'left:92%', u'top:48%']\n",
      "made\n",
      "1\n",
      "shot7 [u'left:94%', u'top:50%']\n",
      "missed\n",
      "0\n",
      "shot8 [u'left:86%', u'top:86%']\n",
      "missed\n",
      "0\n",
      "shot9 [u'left:94%', u'top:50%']\n",
      "made\n",
      "1\n",
      "shot10 [u'left:95%', u'top:52%']\n",
      "made\n",
      "1\n",
      "shot11 [u'left:89%', u'top:58%']\n",
      "missed\n",
      "0\n",
      "shot12 [u'left:94%', u'top:54%']\n",
      "missed\n",
      "0\n",
      "shot13 [u'left:65%', u'top:50%']\n",
      "made\n",
      "1\n",
      "shot14 [u'left:77%', u'top:92%']\n",
      "missed\n",
      "0\n",
      "shot15 [u'left:80%', u'top:96%']\n",
      "made\n",
      "1\n",
      "shot16 [u'left:94%', u'top:50%']\n",
      "missed\n",
      "0\n",
      "shot17 [u'left:64%', u'top:54%']\n",
      "missed\n",
      "0\n",
      "shot20 [u'left:87%', u'top:56%']\n",
      "missed\n",
      "0\n",
      "shot21 [u'left:79%', u'top:74%']\n",
      "missed\n",
      "0\n",
      "shot22 [u'left:74%', u'top:70%']\n",
      "made\n",
      "1\n",
      "shot23 [u'left:92%', u'top:54%']\n",
      "missed\n",
      "0\n",
      "shot24 [u'left:76%', u'top:88%']\n",
      "made\n",
      "1\n",
      "shot25 [u'left:67%', u'top:66%']\n",
      "made\n",
      "1\n",
      "shot26 [u'left:79%', u'top:32%']\n",
      "missed\n",
      "0\n",
      "shot29 [u'left:58%', u'top:28%']\n",
      "missed\n",
      "0\n",
      "shot30 [u'left:87%', u'top:22%']\n",
      "missed\n",
      "0\n",
      "shot31 [u'left:88%', u'top:46%']\n",
      "missed\n",
      "0\n",
      "shot34 [u'left:89%', u'top:54%']\n",
      "made\n",
      "1\n",
      "shot35 [u'left:76%', u'top:86%']\n",
      "missed\n",
      "0\n",
      "shot36 [u'left:94%', u'top:96%']\n",
      "missed\n",
      "0\n",
      "shot40 [u'left:91%', u'top:52%']\n",
      "missed\n",
      "0\n",
      "shot41 [u'left:92%', u'top:56%']\n",
      "made\n",
      "1\n",
      "shot42 [u'left:94%', u'top:50%']\n",
      "missed\n",
      "0\n",
      "shot43 [u'left:92%', u'top:48%']\n",
      "made\n",
      "1\n",
      "shot46 [u'left:90%', u'top:32%']\n",
      "missed\n",
      "0\n",
      "shot47 [u'left:71%', u'top:34%']\n",
      "missed\n",
      "0\n",
      "shot50 [u'left:92%', u'top:54%']\n",
      "missed\n",
      "0\n",
      "shot51 [u'left:88%', u'top:66%']\n",
      "missed\n",
      "0\n",
      "shot52 [u'left:72%', u'top:18%']\n",
      "made\n",
      "1\n",
      "shot53 [u'left:91%', u'top:50%']\n",
      "made\n",
      "1\n",
      "shot54 [u'left:91%', u'top:72%']\n",
      "made\n",
      "1\n",
      "shot55 [u'left:89%', u'top:66%']\n",
      "made\n",
      "1\n",
      "shot56 [u'left:92%', u'top:50%']\n",
      "made\n",
      "1\n",
      "shot57 [u'left:87%', u'top:38%']\n",
      "missed\n",
      "0\n",
      "shot60 [u'left:86%', u'top:16%']\n",
      "made\n",
      "1\n",
      "shot61 [u'left:84%', u'top:72%']\n",
      "missed\n",
      "0\n",
      "shot62 [u'left:85%', u'top:64%']\n",
      "missed\n",
      "0\n",
      "shot63 [u'left:90%', u'top:56%']\n",
      "made\n",
      "1\n",
      "shot64 [u'left:94%', u'top:52%']\n",
      "missed\n",
      "0\n",
      "shot65 [u'left:84%', u'top:62%']\n",
      "missed\n",
      "0\n",
      "shot66 [u'left:67%', u'top:62%']\n",
      "missed\n",
      "0\n",
      "shot69 [u'left:67%', u'top:40%']\n",
      "made\n",
      "1\n",
      "shot70 [u'left:92%', u'top:54%']\n",
      "made\n",
      "1\n",
      "shot71 [u'left:87%', u'top:46%']\n",
      "missed\n",
      "0\n",
      "shot73 [u'left:80%', u'top:60%']\n",
      "missed\n",
      "0\n",
      "shot74 [u'left:92%', u'top:84%']\n",
      "made\n",
      "1\n",
      "shot75 [u'left:66%', u'top:52%']\n",
      "missed\n",
      "0\n",
      "shot78 [u'left:90%', u'top:96%']\n",
      "made\n",
      "1\n",
      "shot79 [u'left:91%', u'top:96%']\n",
      "missed\n",
      "0\n",
      "shot83 [u'left:71%', u'top:84%']\n",
      "made\n",
      "1\n",
      "shot84 [u'left:84%', u'top:74%']\n",
      "missed\n",
      "0\n",
      "shot85 [u'left:74%', u'top:84%']\n",
      "missed\n",
      "0\n",
      "shot88 [u'left:81%', u'top:72%']\n",
      "missed\n",
      "0\n",
      "shot89 [u'left:81%', u'top:44%']\n",
      "made\n",
      "1\n",
      "shot90 [u'left:92%', u'top:46%']\n",
      "made\n",
      "1\n",
      "shot93 [u'left:72%', u'top:84%']\n",
      "missed\n",
      "0\n",
      "shot94 [u'left:69%', u'top:76%']\n",
      "missed\n",
      "0\n",
      "shot97 [u'left:71%', u'top:20%']\n",
      "missed\n",
      "0\n",
      "shot98 [u'left:74%', u'top:16%']\n",
      "made\n",
      "1\n",
      "shot99 [u'left:92%', u'top:54%']\n",
      "made\n",
      "1\n",
      "shot100 [u'left:90%', u'top:50%']\n",
      "missed\n",
      "0\n",
      "shot101 [u'left:75%', u'top:16%']\n",
      "missed\n",
      "0\n",
      "shot102 [u'left:67%', u'top:64%']\n",
      "missed\n",
      "0\n",
      "shot103 [u'left:88%', u'top:70%']\n",
      "made\n",
      "1\n",
      "shot104 [u'left:80%', u'top:70%']\n",
      "missed\n",
      "0\n",
      "shot105 [u'left:76%', u'top:34%']\n",
      "missed\n",
      "0\n",
      "shot106 [u'left:81%', u'top:86%']\n",
      "missed\n",
      "0\n",
      "shot107 [u'left:81%', u'top:96%']\n",
      "missed\n",
      "0\n",
      "shot108 [u'left:71%', u'top:82%']\n",
      "missed\n",
      "0\n",
      "shot113 [u'left:92%', u'top:54%']\n",
      "missed\n",
      "0\n",
      "shot114 [u'left:91%', u'top:66%']\n",
      "missed\n",
      "0\n",
      "shot115 [u'left:78%', u'top:10%']\n",
      "missed\n",
      "0\n",
      "shot116 [u'left:91%', u'top:46%']\n",
      "made\n",
      "1\n",
      "shot117 [u'left:78%', u'top:10%']\n"
     ]
    }
   ],
   "source": [
    "for x in text_home_team.find_all('li'):\n",
    "    print str(x.get('class')[0])\n",
    "    print toBinary(str(x.get('class')[0]))\n",
    "    \n",
    "    text = ('{} {}'.format(x.get('id'), x.get('style').split(';')[-3:-1]))\n",
    "    print text\n",
    "#     text =text.split()\n",
    "#     shot_value = (re.search(r'\\d+', text[0][4:]).group())\n",
    "#     left_value = float((re.search(r'\\d+', text[1][4:]).group()))/100\n",
    "#     top_value = float((re.search(r'\\d+', text[2][4:]).group()))/100\n",
    "#     shot_home.append(shot_value)\n",
    "#     top_home.append(top_value)\n",
    "#     left_home.append(left_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shot Number  Left Position  Top Position     Home Team        Away Team\n",
      "0           0           0.90          0.32  Phoenix Suns  Toronto Raptors\n",
      "1           3           0.94          0.50  Phoenix Suns  Toronto Raptors\n",
      "2           4           0.94          0.56  Phoenix Suns  Toronto Raptors\n",
      "3           5           0.92          0.52  Phoenix Suns  Toronto Raptors\n",
      "4           6           0.92          0.48  Phoenix Suns  Toronto Raptors\n"
     ]
    }
   ],
   "source": [
    "print HomeTeam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "`def url_change(car_make = None ,model = None , price_interval = None, body = None,colors = None):\n",
    "    url = 'http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017'\n",
    "    if car_make != None:\n",
    "        url = url +'/make-'+car_make\n",
    "    if model != None:\n",
    "        url = url + '/model-'+model\n",
    "    if colors != None:\n",
    "        url = url + '/extcolor-'+colors\n",
    "    if body != None:\n",
    "        url = url + '/body-'+body\n",
    "    if price_interval != None:\n",
    "        url = url + '/price-'+price_interval\n",
    "    url = url + '/sort-1/page-'\n",
    "    return url\n",
    "\n",
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def web2var(string):\n",
    "    string = string.replace('+','')\n",
    "    string = string.replace('-','')\n",
    "    return string\n",
    "\n",
    "def var2web(string):\n",
    "    if ' ' in string:\n",
    "        string = string.replace(' ','+')\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "carname = []\n",
    "# print key_list[11]\n",
    "# print Car_Make[11]\n",
    "# print modelDictionary[key_list[11]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#@Deprecated\n",
    "# def Total_Trucks(soup, cartype, body=None): \n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "def Total_Cars(soup, cartype):\n",
    "    total_cars = str(soup.body.h1.text)\n",
    "    print total_cars\n",
    "    total_cars = total_cars.replace(',','')\n",
    "    total_cars = int(re.search(r'\\d+', total_cars).group())\n",
    "#   total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "    print total_cars\n",
    "    total_cars= int(total_cars)\n",
    "    return total_cars\n",
    "    \n",
    "#46010 is total\n",
    "#i = 1\n",
    "#haven't done Chevrolet because they have a lot (175k)\n",
    "# i = 12 is cheverolet\n",
    "#for i in range(12,len(Car_Make)):\n",
    "\n",
    "for i in range(1,len(Car_Make)):\n",
    "    url = url_change(Car_Make[i])\n",
    "    soup = Open_Browser(url, i)\n",
    "    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    print url;\n",
    "    #     print total_cars\n",
    "    if total_cars > 3000:\n",
    "        #model iteration\n",
    "        for h in range(0 , len(modelDictionary[key_list[i]])):\n",
    "            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h])\n",
    "            soup = Open_Browser(url, i)\n",
    "            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "            print url\n",
    "            print total_cars\n",
    "            if total_cars > 3000:\n",
    "                for k in range(0 , len(Price_Interval)):\n",
    "                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k])\n",
    "                    soup = Open_Browser(url, i)\n",
    "                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                    print url\n",
    "                    print total_cars\n",
    "                    if total_cars > 3000:\n",
    "                        for l in range(0 , len(Body)):\n",
    "                            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l])\n",
    "                            soup = Open_Browser(url, i)\n",
    "                            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                            print url\n",
    "                            print total_cars\n",
    "                            if total_cars > 3000:\n",
    "                                for j in range(0,len(Colors)):\n",
    "                                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l],Colors[j])\n",
    "                                    soup = Open_Browser(url, i)\n",
    "                                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                                    print url\n",
    "                                    print total_cars\n",
    "                            else:\n",
    "                                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                                    soup = Open_Browser(url,page)\n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                        carname.append(row.text)    \n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                        price.append(row.text[8:])\n",
    "                                    print page\n",
    "                    else:\n",
    "                        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                            soup = Open_Browser(url,page)\n",
    "                            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                carname.append(row.text)    \n",
    "                            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                price.append(row.text[8:])\n",
    "                            print page  \n",
    "            else:\n",
    "                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                    soup = Open_Browser(url,page)\n",
    "                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                        carname.append(row.text)    \n",
    "                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                        price.append(row.text[8:])\n",
    "                    print page\n",
    "    else:\n",
    "        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "            soup = Open_Browser(url,page)\n",
    "            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                carname.append(row.text)    \n",
    "            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                price.append(row.text[8:])\n",
    "            print page\n",
    "\n",
    "\n",
    "print 'Done'\n",
    "                            \n",
    "#     count = count +1\n",
    "#     url_change = url + str(i)\n",
    "#     br.open(url_change)\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "#         carname.append(row.text)    \n",
    "#     for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "#         price.append(row.text[8:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ####Browser mechanize functionality\n",
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "\n",
    "\n",
    "# #Used to count and figure out which ones are over 3000 even after Body type\n",
    "# def Open_Browser(url, page):\n",
    "#     br.open(url+str(page))\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     return soup\n",
    "\n",
    "# def Total_Trucks(soup, cartype, body=None):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "# def Total_Cars(soup, cartype):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "    \n",
    "# #46010 is total\n",
    "# for i in range(1,len(Car_Make)):\n",
    "#     url = url_change(Car_Make[i])\n",
    "#     soup = Open_Browser(url, i)\n",
    "#     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#     print url;\n",
    "#     print total_cars\n",
    "#     if total_cars > 3000:\n",
    "#         print total_cars > 3000\n",
    "#         for j in range(1,len(Price_Interval)):\n",
    "#             url = url_change(Car_Make[i], Price_Interval[j])\n",
    "#             soup = Open_Browser(url, i)\n",
    "#             total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#             print url\n",
    "#             print total_cars\n",
    "# #     else:\n",
    "#             if total_cars > 3000:\n",
    "#                 for k in range(1 , len(Colors)):\n",
    "#                     url = url_change(Car_Make[i], Price_Interval[j], Colors[k])\n",
    "#                     soup = Open_Browser(url, i)\n",
    "#                     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#                     print url\n",
    "#                     print total_cars\n",
    "# #             else:\n",
    "#                     if total_cars > 3000:\n",
    "#                         for l in range(1 , len(Body)):\n",
    "#                             url = url_change(Car_Make[i], Price_Interval[j], Colors[k],Body[l])\n",
    "#                             soup = Open_Browser(url, i)\n",
    "#                             total_cars = Total_Trucks(soup, Car_Make[i], Body[l])\n",
    "#                             print url\n",
    "#                             print total_cars\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################Write Dataframe to .csv\n",
    "output = pd.DataFrame(price,carname)\n",
    "#print(output)\n",
    "output.to_csv('CarPriceDistribution.csv', sep = ',', encoding = 'utf-8' )\n",
    "\n",
    "print len(price)\n",
    "#print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
