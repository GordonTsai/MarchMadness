{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pprint  \n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import mechanize \n",
    "import time\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "#r = requests.get('http://www.listingallcars.com/results/New')\n",
    "#data = r.text\n",
    "#soup = BeautifulSoup(data)\n",
    "#for link in sou\n",
    "#p.find_all('a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_change(car_make = None ,model = None , price_interval = None, body = None,colors = None):\n",
    "    url = 'http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017'\n",
    "    if car_make != None:\n",
    "        url = url +'/make-'+car_make\n",
    "    if model != None:\n",
    "        url = url + '/model-'+model\n",
    "    if colors != None:\n",
    "        url = url + '/extcolor-'+colors\n",
    "    if body != None:\n",
    "        url = url + '/body-'+body\n",
    "    if price_interval != None:\n",
    "        url = url + '/price-'+price_interval\n",
    "    url = url + '/sort-1/page-'\n",
    "    return url\n",
    "\n",
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def web2var(string):\n",
    "    string = string.replace('+','')\n",
    "    string = string.replace('-','')\n",
    "    return string\n",
    "\n",
    "def var2web(string):\n",
    "    if ' ' in string:\n",
    "        string = string.replace(' ','+')\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "carname = []\n",
    "# print key_list[11]\n",
    "# print Car_Make[11]\n",
    "# print modelDictionary[key_list[11]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,653 New  Acura Cars for Sale in the USA\n",
      "18653\n",
      "http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017/make-Acura/sort-1/page-\n",
      "0 New Acura CL Cars for Sale in the USA\n",
      "0\n",
      "http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017/make-Acura/model-CL/sort-1/page-\n",
      "0\n",
      "2,853 New Acura ILX Cars for Sale in the USA\n",
      "2853\n",
      "http://www.everycarlisted.com/search/vehicle_condition-New/year-2017-2017/make-Acura/model-ILX/sort-1/page-\n",
      "2853\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "####Browser mechanize functionality\n",
    "br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "\n",
    "def Open_Browser(url, page):\n",
    "    br.open(url+str(page))\n",
    "    response = br.response()\n",
    "    soup = BeautifulSoup(response,\"html.parser\")\n",
    "    return soup\n",
    "\n",
    "#@Deprecated\n",
    "# def Total_Trucks(soup, cartype, body=None): \n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "def Total_Cars(soup, cartype):\n",
    "    total_cars = str(soup.body.h1.text)\n",
    "    print total_cars\n",
    "    total_cars = total_cars.replace(',','')\n",
    "    total_cars = int(re.search(r'\\d+', total_cars).group())\n",
    "#   total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "    print total_cars\n",
    "    total_cars= int(total_cars)\n",
    "    return total_cars\n",
    "    \n",
    "#46010 is total\n",
    "#i = 1\n",
    "#haven't done Chevrolet because they have a lot (175k)\n",
    "# i = 12 is cheverolet\n",
    "#for i in range(12,len(Car_Make)):\n",
    "\n",
    "for i in range(1,len(Car_Make)):\n",
    "    url = url_change(Car_Make[i])\n",
    "    soup = Open_Browser(url, i)\n",
    "    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "    print url;\n",
    "    #     print total_cars\n",
    "    if total_cars > 3000:\n",
    "        #model iteration\n",
    "        for h in range(0 , len(modelDictionary[key_list[i]])):\n",
    "            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h])\n",
    "            soup = Open_Browser(url, i)\n",
    "            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "            print url\n",
    "            print total_cars\n",
    "            if total_cars > 3000:\n",
    "                for k in range(0 , len(Price_Interval)):\n",
    "                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k])\n",
    "                    soup = Open_Browser(url, i)\n",
    "                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                    print url\n",
    "                    print total_cars\n",
    "                    if total_cars > 3000:\n",
    "                        for l in range(0 , len(Body)):\n",
    "                            url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l])\n",
    "                            soup = Open_Browser(url, i)\n",
    "                            total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                            print url\n",
    "                            print total_cars\n",
    "                            if total_cars > 3000:\n",
    "                                for j in range(0,len(Colors)):\n",
    "                                    url = url_change(Car_Make[i], modelDictionary[key_list[i]][h], Price_Interval[k],Body[l],Colors[j])\n",
    "                                    soup = Open_Browser(url, i)\n",
    "                                    total_cars = Total_Cars(soup, Car_Make[i])\n",
    "                                    print url\n",
    "                                    print total_cars\n",
    "                            else:\n",
    "                                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                                    soup = Open_Browser(url,page)\n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                        carname.append(row.text)    \n",
    "                                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                        price.append(row.text[8:])\n",
    "                                    print page\n",
    "                    else:\n",
    "                        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                            soup = Open_Browser(url,page)\n",
    "                            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                                carname.append(row.text)    \n",
    "                            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                                price.append(row.text[8:])\n",
    "                            print page  \n",
    "            else:\n",
    "                for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "                    soup = Open_Browser(url,page)\n",
    "                    for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                        carname.append(row.text)    \n",
    "                    for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                        price.append(row.text[8:])\n",
    "                    print page\n",
    "    else:\n",
    "        for page in range(1,int(math.ceil(total_cars/30.0))+1):\n",
    "            soup = Open_Browser(url,page)\n",
    "            for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "                carname.append(row.text)    \n",
    "            for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "                price.append(row.text[8:])\n",
    "            print page\n",
    "\n",
    "\n",
    "print 'Done'\n",
    "                            \n",
    "#     count = count +1\n",
    "#     url_change = url + str(i)\n",
    "#     br.open(url_change)\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "#         carname.append(row.text)    \n",
    "#     for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "#         price.append(row.text[8:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ####Browser mechanize functionality\n",
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "\n",
    "\n",
    "# #Used to count and figure out which ones are over 3000 even after Body type\n",
    "# def Open_Browser(url, page):\n",
    "#     br.open(url+str(page))\n",
    "#     response = br.response()\n",
    "#     soup = BeautifulSoup(response,\"html.parser\")\n",
    "#     return soup\n",
    "\n",
    "# def Total_Trucks(soup, cartype, body=None):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     if body == 'suv' or body =='pickup':\n",
    "#         total_cars = total_cars[0:len(total_cars)-32-len(cartype)].replace(',','')\n",
    "#     else:\n",
    "#         total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "\n",
    "# def Total_Cars(soup, cartype):\n",
    "#     total_cars = str(soup.body.h1.text)\n",
    "#     print total_cars\n",
    "#     total_cars = total_cars[0:len(total_cars)-30-len(cartype)].replace(',','')\n",
    "#     print total_cars\n",
    "#     total_cars= int(total_cars)\n",
    "#     return total_cars\n",
    "    \n",
    "# #46010 is total\n",
    "# for i in range(1,len(Car_Make)):\n",
    "#     url = url_change(Car_Make[i])\n",
    "#     soup = Open_Browser(url, i)\n",
    "#     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#     print url;\n",
    "#     print total_cars\n",
    "#     if total_cars > 3000:\n",
    "#         print total_cars > 3000\n",
    "#         for j in range(1,len(Price_Interval)):\n",
    "#             url = url_change(Car_Make[i], Price_Interval[j])\n",
    "#             soup = Open_Browser(url, i)\n",
    "#             total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#             print url\n",
    "#             print total_cars\n",
    "# #     else:\n",
    "#             if total_cars > 3000:\n",
    "#                 for k in range(1 , len(Colors)):\n",
    "#                     url = url_change(Car_Make[i], Price_Interval[j], Colors[k])\n",
    "#                     soup = Open_Browser(url, i)\n",
    "#                     total_cars = Total_Cars(soup, Car_Make[i])\n",
    "#                     print url\n",
    "#                     print total_cars\n",
    "# #             else:\n",
    "#                     if total_cars > 3000:\n",
    "#                         for l in range(1 , len(Body)):\n",
    "#                             url = url_change(Car_Make[i], Price_Interval[j], Colors[k],Body[l])\n",
    "#                             soup = Open_Browser(url, i)\n",
    "#                             total_cars = Total_Trucks(soup, Car_Make[i], Body[l])\n",
    "#                             print url\n",
    "#                             print total_cars\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# br = mechanize.Browser(factory=mechanize.RobustFactory())\n",
    "# cartype = 'Rolls-Royce'\n",
    "# url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-Chevrolet/year-2017-2017/sort-1/page-'\n",
    "# #url = 'http://www.everycarlisted.com/search/vehicle_condition-New/make-'+cartype+'/year-2017-2017/page-'\n",
    "# br.open(url+str(1))\n",
    "# response = br.response()\n",
    "# soup = BeautifulSoup(response,\"html.parser\")\n",
    "# #print soup.prettify()\n",
    "\n",
    "\n",
    "# price = []\n",
    "# carname = []\n",
    "# count = 0\n",
    "\n",
    "# total_cars = str(soup.body.h1.text)\n",
    "# total_cars = int(total_cars[0:len(total_cars)-30-len(cartype)].replace(',',''))\n",
    "# # print soup.find_all('select',{\"class\":\"col-md-12 form-control\"})\n",
    "# for row in soup.find_all('select',{\"id\":\"SearchForm_carModel\"}):\n",
    "#     print row.text\n",
    "# #if total_cars\n",
    "\n",
    "# # soup = BeautifulSoup(response,\"html.parser\")\n",
    "# # for row in soup.find_all('div',{ \"class\" : \"sansBold font14 title\" }):\n",
    "# #     carname.append(row.text)    \n",
    "# # for row in soup.find_all('div',{ \"class\" : \"col-sm-6 col-xs-6 price\" }):\n",
    "# #     price.append(row.text[8:])\n",
    "    \n",
    "# #print price\n",
    "# #print total_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################Write Dataframe to .csv\n",
    "output = pd.DataFrame(price,carname)\n",
    "#print(output)\n",
    "output.to_csv('CarPriceDistribution.csv', sep = ',', encoding = 'utf-8' )\n",
    "\n",
    "print len(price)\n",
    "#print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
